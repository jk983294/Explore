/**
 * http://www.simnow.com.cn/product.action
 * http://www.sfit.com.cn/5_2_DocumentDown.htm
 * https://link.zhihu.com/?target=http%3A//download.csdn.net/detail/u010908140/9656275
 * http://download.csdn.net/detail/u010908140/9656275
 * http://download.csdn.net/detail/u010908140/9656314
 */

# file path: /functions.h
#ifndef FUNCTIONS_H
#define FUNCTIONS_H

void print_hello();
int factorial(int n);

#endif

# file path: /factorial.cpp
#include "functions.h"

int factorial(int n){

   if(n!=1){
      return(n * factorial(n-1));
   }
   else return 1;
}


# file path: /hello.cpp
#include <iostream>

using namespace std;

#include "functions.h"

void print_hello(){
   cout << "Hello World!";
}


# file path: /main.cpp
#include <iostream>

using namespace std;

#include "functions.h"

int main(){
   print_hello();
   cout << endl;
   cout << "The factorial of 5 is " << factorial(5) << endl;
   return 0;
}


# file path: /cmd.txt
trivial way to compile:
g++  main.cpp hello.cpp factorial.cpp -o hello

Macros
$@		he name of the file to be made.
$? 	 the names of the changed dependents.
$< 	the name of the related file that caused the action.
$* 	the prefix shared by target and dependent files
AS	Program for compiling assembly files; default is `as'.
CC	Program for compiling C programs; default is `cc'.
CXX	Program for compiling C++ programs; default is `g++'.
CPP	Program for running the C preprocessor, with results to standard output; default is `$(CC) -E'.
LINT	Program to use to run lint on source code; default is `lint'.
RM	Command to remove a file; default is `rm -f'.
CFLAGS	Extra flags to give to the C compiler.
CXXFLAGS	Extra flags to give to the C compiler.
CPPFLAGS	Extra flags to give to the C preprocessor and programs, which use it (such as C and Fortran compilers).
LDFLAGS	Extra flags to give to compilers when they are supposed to invoke the linker, `ld'.
LINTFLAGS	Extra flags to give to lint.

make all − It compiles everything so that you can do local testing before installing applications.
make install − It installs applications at right places. But watch out that things are installed in the right place for your system.
make clean − It clean applications up, gets rid of the executables, any temporary files, object files, etc.

Makefile Implicit Rules
# make x out of x.c -- run cc on x.c and call the output x
.cpp:
	$(CC) $(CFLAGS) $@.cpp $(LDFLAGS) -o $@
# construction of .o (object) files out of .cpp (source files)
.cpp.o:
	$(CC) $(CFLAGS) -c $*.cpp

# Suffix Rules
# make a .o file from a .c file
.c.o:
	$(CC) $(CFLAGS) -c $<

# recompile avoid
# make checks its object file and compares the time stamps.
# If source file is newer than the object file, then it generates new object file assuming that the source file has been changed.
make -t												# mark all the object files as up to date
make -o header_file							# marks a specified file as "old"


make -f your-makefile-name


# file path: /append_syntax.mk
OBJECTS = main.o hello.o
OBJECTS += factorial.o
hello: $(OBJECTS)
	cc $(OBJECTS) -o hello
hellp.o: functions.h
main.o: functions.h
factorial.o: functions.h

install:
	@echo You must be root to install

clean :
	rm main.o factorial.o hello.o hello


# file path: /continuation_line.mk
# If you indicate just the .h files in the dependency line, make will know that the corresponding .c file is already required
OBJECTS = main.o \
	hello.o \
	factorial.o

hello: $(OBJECTS)
	cc $(OBJECTS) -o hello
hellp.o: functions.h
main.o: functions.h
factorial.o: functions.h

install:
	@echo You must be root to install

clean :
	rm main.o factorial.o hello.o hello



# file path: /directive.mk
# Conditionals Directives
libs_for_gcc = -lgnu
normal_libs =

foo: $(objects)
ifeq ($(CC),gcc)
	$(CC) -o foo $(objects) $(libs_for_gcc)
else
	$(CC) -o foo $(objects) $(normal_libs)
endif

#  Include Directive
# suspend reading the current makefile and read one or more other makefiles before continuing
include a.mk b.mk c.mk

# The override Directive
# set the variable in the makefile even though it was set with a command argument
override variable = value
override variable := value


# file path: /shorten.mk
SHELL = /bin/sh

OBJECTS =  main.o factorial.o hello.o
CFLAG = -Wall -g
CC = gcc
INCLUDE =
LIBS = -lm

# If you indicate just the .h files in the dependency line, make will know that the corresponding .c file is already required
hello: $(OBJECTS)
	cc $(OBJECTS) -o hello
hellp.o: functions.h
main.o: functions.h
factorial.o: functions.h

install:
	@echo You must be root to install

clean :
	rm main.o factorial.o hello.o hello



# file path: /verbose.mk
INCLUDES = -I "/home/tutorialspoint/header"
CC = gcc
LIBS =  -lm
CFLAGS = -g -Wall

# dependent on main.o, factorial.o, and hello.o files.
# Hence, whenever there is a change in any of these object files, make will take action.
hello: main.o factorial.o hello.o
	$(CC) main.o factorial.o hello.o -o hello

main.o: main.cpp functions.h
	$(CC) $(CFLAGS) -c main.cpp

factorial.o: factorial.cpp functions.h
	$(CC) $(CFLAGS) -c factorial.cpp

hello.o: hello.cpp functions.h
	$(CC) $(CFLAGS) -c hello.cpp

install:
	@echo You must be root to install

clean :
	rm main.o factorial.o hello.o hello


# file path: /makefile
SHELL = /bin/sh

OBJECTS =  main.o factorial.o hello.o
CFLAG = -Wall -g
CC = gcc
INCLUDE =
LIBS = -lm

# If you indicate just the .h files in the dependency line, make will know that the corresponding .c file is already required
hello:${OBJ}
	${CC} ${CFLAGS} ${INCLUDES} -o $@ ${OBJS} ${LIBS}

clean:
	-rm -f *.o core *.core

.cpp.o:
	${CC} ${CFLAGS} ${INCLUDES} -c $<

install:
	@echo You must be root to install



# file path: /random
https://github.com/ipreacher/tricks/tree/master/Stock_WeChat
https://github.com/littlecodersh/ItChat

# file path: /cpp/keyword/typename.cpp
#include <iostream>
#include <vector>

using namespace std;

/**
 * qualified name: std::cout
 * unqualified name: cout
 * a dependent name is a name that depends on a template parameter. like T, vector<T>, vector<T>::iterator
 * typename remove the ambiguity
 * typename T::iterator is a type name, not a value
 */

template <class T>
class MyClass {
	int i;								// non-dependent name
	vector<int> vi;						// non-dependent name
	vector<int>::iterator vitr;			// non-dependent name

	T t;									// dependent name
	vector<T> vt;						// dependent name
	typename vector<T>::iterator viter;	// dependent name

	typedef T another_name_for_T;		// another_name_for_T still considered a dependent name
};

template <class T>
void foo() {
	T::iterator * iter;
	cout << "T::iterator means nested type name depend on T" << endl;
}

template <class T>
void bar() {
	typename T::iterator * iter;
	cout << "T::iterator means nested type name depend on T" << endl;
}

template <class T>
void meow() {
	typedef typename T::iterator iterator_type;
	iterator_type * iter;
	cout << "T::iterator means nested type name depend on T" << endl;
}

class ContainsType {
public:
	class iterator {
	};
};

class ContainsValue {
public:
	static int iterator;
};

int main(){
	foo<ContainsType>();
	//foo<ContainsValue>();			// won't get compiled
	bar<ContainsType>();
	//bar<ContainsValue>();			// won't get compiled
	return 0;
}

# file path: /cpp/lib/pthread/mutex.cpp
#include <pthread.h>
#include <stdio.h>

#define NUM_THREADS 4

pthread_mutex_t count_mutex;
int count;

void increment_count()
{
    pthread_mutex_lock(&count_mutex);
    ++count;
    pthread_mutex_unlock(&count_mutex);
}

void* threadFunc(void *pArg)
{
    int myNum = *((int *)pArg);
    printf("Thread number %d\n", myNum);

    for (int i = 0; i < 100; i++)
    {
        increment_count();
    }
    return 0;
}

int main()
{
    pthread_t tid[NUM_THREADS];

    for (int i = 0; i < NUM_THREADS; i++)
    {
        int local = i;
        pthread_create(&tid[i], NULL, threadFunc, &local);
    }

    for (int i = 0; i < NUM_THREADS; i++)
    {
        pthread_join(tid[i], NULL);
    }

    printf("final count %d\n", count);
    return 0;
}

# file path: /cpp/lib/pthread/producer_consumer.cpp
#include <pthread.h>
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>

/**
 * producer consumer
 */

#define BUF_SIZE 3                                              // size of shared buffer

int buffer[BUF_SIZE];                                           // shared buffer
int add_pos = 0;                                                // next add position
int remove_pos = 0;                                             // next remove position
int data_count = 0;                                             // total data count

pthread_mutex_t m = PTHREAD_MUTEX_INITIALIZER;                  // mutex for buffer
pthread_cond_t c_consumer = PTHREAD_COND_INITIALIZER;           // consumer waits on this condition variable
pthread_cond_t c_producer = PTHREAD_COND_INITIALIZER;           // producer waits on this condition variable

void* producer_thread(void *param)
{
    int next_data = 0;
    while(true) {
        sleep(2);

        pthread_mutex_lock(&m);
        if(data_count == BUF_SIZE) {                            // buffer is full, wait for consumer's signal
            pthread_cond_wait(&c_producer, &m);
        }
        buffer[add_pos] = next_data;
        add_pos = (add_pos + 1) % BUF_SIZE;
        ++data_count;
        pthread_mutex_unlock(&m);

        pthread_cond_signal(&c_consumer);                       // signal consumer to consume

        printf("producer: insert %d\n", next_data);
        fflush(stdout);
        ++next_data;
    }
    return 0;
}

void* consumer_thread(void *param)
{
    int data;
    while(true) {
        pthread_mutex_lock(&m);
        if(data_count == 0) {                                   // buffer is empty, wait for producer's signal
            pthread_cond_wait(&c_consumer, &m);
        }
        data = buffer[remove_pos];
        remove_pos = (remove_pos + 1) % BUF_SIZE;
        --data_count;
        pthread_mutex_unlock(&m);

        pthread_cond_signal(&c_producer);                       // signal producer to produce

        printf("consumer: value %d\n", data);
        fflush(stdout);
    }
    return 0;
}

int main(){
    pthread_t producer, consumer;
    pthread_create(&producer, NULL, producer_thread, NULL);
    pthread_create(&consumer, NULL, consumer_thread, NULL);
    pthread_join(producer, NULL);
    pthread_join(consumer, NULL);
    return 0;
}

# file path: /cpp/lib/pthread/pthread.cpp
#include <pthread.h>
#include <stdio.h>

#define NUM_THREADS 4

void* threadFunc(void *pArg)
{
    int myNum = *((int *)pArg);
    printf("Thread number %d\n", myNum);
    return 0;
}

int main()
{
    pthread_t tid[NUM_THREADS];

    for (int i = 0; i < NUM_THREADS; i++)
    {
        int local = i;
        pthread_create(&tid[i], NULL, threadFunc, &local);
    }

    for (int i = 0; i < NUM_THREADS; i++)
    {
        pthread_join(tid[i], NULL);
    }
    return 0;
}

# file path: /cpp/lib/pthread/compile.cmd
g++ -o main *.cpp -pthread

# file path: /cpp/template/meta/compute/value/binary.cpp
#include <iostream>

using namespace std;

template <unsigned long N>
struct binary
{
	static unsigned const value = binary<N/10>::value * 2 + N % 10;
};

template <>
struct binary<0>
{
	static unsigned const value = 0;
};

int main(){
	cout << binary<10010>::value << endl;
	cout << binary<1>::value << endl;
	cout << binary<0>::value << endl;
	return 0;
}

# file path: /cpp/template/typerich/dimension.cpp
#include <iostream>
#include <vector>

using namespace std;

/**
* type rich programming
* using template and suffix literal operator overloading
* dimension analysis
* length, mass, time (m, Kg, s)
*/

template<int M, int K, int S>
struct Unit {
	static const int m = M;
	static const int k = K;
	static const int s = S;
};

template< typename UNIT>
struct Value {
	//the raw naked value
	double val;
	//retain access to unit's values after first stage compilation
	static constexpr int getM(){ return UNIT::m; }
	static constexpr int getK(){ return UNIT::k; }
	static constexpr int getS(){ return UNIT::s; }

	//constructors
	explicit Value(double d): val(d){}
	constexpr Value(): val(0){}
};

using second = Unit<0,0,1>;
using second2 = Unit<0,0,2>;
using meter = Unit<1,0,0>;
using Time = Value<second>;
using Distance = Value<meter>;
using Acceleration = Value<Unit<1,0,-2>>;	//global scope

Time operator"" _s (double d){
	return Time(d);
};
Distance operator"" _m (double d){
	return Distance(d);
};
Value<second2> operator"" s2 (long double d){	//overloaded second square suffix operator
	return Value<second2>(d);
};

template< typename UNIT>
Value<UNIT> operator +( Value<UNIT> another ){
	return Value<UNIT>(val + another.val);
}
template< typename OTHER >
Value<Unit<getM()-OTHER::getM(),getK()-OTHER::getK(),getS()-OTHER::getS()>> operator /(OTHER other){
	Value<Unit<getM()-other.getM(),getK()-other.getK(),getS()-other.getS()>> result(val / other.val);
	return result;
}

int main(){
	Time time = 1.0_s;
	Distance d = 1.4_m;
	Acceleration acc1 = 1m/2.4s2;
	Acceleration acc2 = 4.8m/2.1s2;
	Acceleration acc3 = acc1 + acc2;
	Acceleration acc = 8m/3.3s2;
	return 0;
}

# file path: /perl/main.pl
use strict;
use warning;

sub main {
    print "hello world";
}

main();

# file path: /perl/execution.pl
# active perl / strawberry perl
# perl script.pl
# perl -e 'print "Hello World\n"'

# file path: /perl/io/download.pl
use strict;
use warning;

use LWP::Simple;

sub main {
    print "downloading...\n";
    # print get("www.baidu.com");

    my $code = getstore("www.baidu.com", "home.html");

    if($code == 200) {
        print "success\n";
    } else {
        print "failed\n";
    }

    print "finished\n";
}

main();



# random
OS
context switch cost: 1) number of cycles for load & store instructions 2) cold cache, cache missing
process creation:
1) fork, copy the parent PCB into new child PCB, child continues execution at the instruction after fork
2) exec, replace child image, load new program and start from first instruction
init is the parent of all processes in UNIX-based OS, Zygote is the parent of all APP processes in Android OS
IPC
1) communication channel like shared buffer,  benefit is OS manages, exactly the same API, downside is overhead, copy data between user mode and kernel mode
2) shared memory, OS establishes a shared channel and maps it into each process address space, benefit is fast since no kernel data copy overhead (but the shared memory setup is expensive, only when lots of messages, the amortised cost is cheap), downside is coder need to handle the complexity for no common API
thread out performance process: 1) thread share the same address space, it means the cost for allocate address space is only once 2) data passing among thread (usually shared variables) is cheaper than process (IPC)
单核使用thread有优势吗？有用，比如thread1读取disk，thread2可以做计算
Join semantic: child_status = join(child_thread), called by parent, wait for child thread to finish, then retrieve the result of child status
condition variable: 1) wait(mutex, cond), mutex is automatically released and go to wait queue, then re-acquire mutex for critical section 2) signal(cond), wake up one thread on waiting list 3) broadcast(cond), wake up all waiting threads
spurious wake-ups: unnecessary wake up
dead lock avoid: 1) get all locks at one shot 2) get locks in the same order (say A first then B)
multi-threading pattern
1) Boss/Worker, worker thread pool, Boss is the producer to produce task into queue, workers are consumers. locality give better performance, worker could be specialized to one task
2) Pipeline: use thread pool, use shared buffer based communication for passing data across stages
3) layered pattern
thread related data structures: 
1) PCB: [1] hard process state: virtual address mapping [2] light process state: signals, sys call args
2) user level thread (ULT): UL thread ID, UL registers, thread stack
3) kernel level thread (KLT): stack, registers
thread management visibility:
1) kernel sees: KLTs, CPUs, KL scheduler
2) UL thread library sees: ULTs, available KLTs(decided by user mode thread / kernel mode thread mapping)
thread pinning: bound one user mode thread to specified kernel mode thread, this improves locality
adaptive mutex: on multi-CPU system, it is better to spin rather than block when the owner of the mutex is running on another CPU and critical section is short
interrupts: events generated externally by hardware(IO, timer), asynchronously
signals: triggered by code, synchronously or asynchronously
interrupts vs signals similarity: 1) unique ID 2) can be masked, per-CPU interrupt mask(when masked, hardware interrupt will not be delivered to CPU), per-process signal mask(when masked, kernel sees mask and will not interrupt corresponding thread)
interrupt can be directed to any CPU that has them enabled. we can designate one core to handle the interrupt so that other core won't get disturbed
type of signals: 1) one shot signal: n signals pending == 1 signal pending, must be explicitly re-enabled 2) real time signals, if n signals raised, then handler is called n times
interrupt handling can be divided two parts: 1) top half, execute in current stack, no need to launch another thread, fast, non-block, min amount of processing 2) bottom half, execute in another thread, arbitrary complexity
linux thread support: 1) execution context abstraction is task 2) native POSIX threads library (NPTL), 1:1 model, 1 ULT : 1 KLT
thread benefits: 1) parallelization, speed up 2) specialization, hot cache 3) efficiency, lower memory requirement and cheaper synchronization 4) hide latency of I/O
performance metrics(measurable quantity): 
1) wait time 2) throughput 3) CPU utilization 4) execution time 5) platform efficiency 6) performance per money 
7) performance per power 8) percentage of SLA violations 9) client perceived performance 10) average resource usage
11) bandwidth (bytes / time) 12) connection rate (request / time)
Are threads useful? it depends on: 1) metrics 2) workload
event driven model, state machine, single address space, single process, single thread of control, event dispatcher dispatch event event handlers, in event handler, when meet sync, it will give control back to dispatcher and put itself into block queue, helper is process which handle the block I/O operations
multiple thread(MT) VS multiple process(MP) VS event driven model(EDM): 
MP, good: simple programming; bad: high memory usage, costly context switch, costly to maintain shared state across process
MT, good: shared address space, shared state, cheap context switch; bad: not simple implementation, require synchronization, OS underlying support for threads
EDM, good: single address space, single flow of control, smaller memory requirement, no context switch, no synchronization, asynchronous I/O; bad: applicability to certain classes of applications, not applicable to arbitrary applications, event routing on multi CPU systems
Shortest Job First(SJF) gives best waiting time metric
priority inversion: temp boost priority of mutex owner, then lower priority again when releasing mutex
time slice: more I/O intensive, less time slice is better, more CPU intensive, more time slice is better
multi-level feedback queue(MLFQ), different policy for different level
linux O(1) scheduler, constant time to select/add task, real time (0-99), time sharing (100-139), user processes, default priority 120, nice value (-20-19), different time slice for different priority, user's program tend to CPU intensive which should be given high CPU time slice
linux CFS(completely fair scheduler), red-black tree, order by "vruntime"(time spent on CPU), select task O(1), add task O(log N)
multi-CPU, each CPU has private caches (L1, L2), the last level cache(LLC) may or may not be shared, DRAM is shared by CPUs
multi-core, each core has privete L1, cores within same CPU share LLC and memory
cache affinity important, hierarchical scheduler architecture, run-queue load balance for different CPUs, also NUMA(non-uniform memory access)-aware scheduling used for support
hyper-threading(hardware multi-threading, chip multi-threading, simultaneous multi-threading), still 1 CPU but with very fast context switch, because multiple hardware supported(several sets of registers)
hyper-threading scheduler use hardware informations, CPI(cycles-per-instruction), memory bound task tend to high CPI, CPU bound task tend to low CPI
memory management hardware support:
1) MMU(memory management unit): translate virtual to physical addresses
2) register: pointer to page table, segment base& limit size
3) cache: TLB(translation lookaside buffer)
4) translation: actual physical address generation




C++模板元编程
编译期无法实现迭代，因此，对于元程序，递归是常用的手段
我们可以通过引入一个额外的间接层来解决任何问题。由于primitve不能有内部嵌套类型，所以引入traits
traits: value_type, reference, pointer, difference_type, iterator_category


趋势交易逻辑存在的前提是产业泡沫（资本逐利）、人类心理因素、及供需不平衡
高频交易，他的存在前提是，市场具备有足够的流动性，场内成交价与场外具有延迟
投机就是看似有迹可循，但其实概率完全是随机的。而赌博是看似随机，而其实概率是恒定的，或者说是概率变化是有迹可循
知道和做到之间，隔了10000次的刻意练习
知识的敌人不是无知，而是拥有知识的错觉
赚钱的导数才是决定你高兴程度的主要条件
These violent delights have violent ends

博学之，审问之，慎思之，明辨之，笃行之


免费自动交易工具：网格交易 - 助你在A股市场里网罗天下
http://www.55188.com/viewthread.php?tid=7238099&extra=&page=1
万字长文解析全球商品期货量化交易策略
http://www.puoke.com/sns/articleContent.php?id=23073

ctrl + w             close current window
win + L             lock
win + E             resource manager
win + D             hide everything
win + tab          3D tab window
win + +             zoom in
win + R             run something
psr.exe             record
osk                   on-screen keyboard





贫穷的本质
当穷人可以多买一点儿食物时，他们并不注重用所有投入换取更多能量，相反，他们会选择买一些口味更好、价钱更高的食物
穷人在选择食品时，主要考虑的并不是价格是否便宜，而不是有无营养价值，而是食物的口味怎么样
穷人的生活中，还有比食物更重要的东西，大量发展中国家的穷人会花很多钱来置办婚礼、嫁妆、洗礼等，这很可能是怕丢面子的结果
穷人的问题并不在食物的数量，而在于食物的质量，特别是微量元素的缺失
穷人常常把钱花在昂贵的治疗上，而不是廉价的预防上
